{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1ae5b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 865 rows to ../csv_files/Armenia_subsampled_output.csv\n",
      "Wrote 547 rows to ../csv_files/Yerevan_subsampled_output.csv\n",
      "Wrote 542 rows to ../csv_files/Nagorno-Karabakh_subsampled_output.csv\n",
      "Wrote 513 rows to ../csv_files/Adana_subsampled_output.csv\n",
      "Wrote 472 rows to ../csv_files/Armenians_subsampled_output.csv\n",
      "Wrote 358 rows to ../csv_files/Armenian_language_subsampled_output.csv\n",
      "Wrote 338 rows to ../csv_files/Mount_Ararat_subsampled_output.csv\n",
      "Wrote 324 rows to ../csv_files/Armenian_genocide_recognition_subsampled_output.csv\n",
      "Wrote 313 rows to ../csv_files/Shusha_subsampled_output.csv\n",
      "Wrote 302 rows to ../csv_files/Dolma_subsampled_output.csv\n",
      "Wrote 272 rows to ../csv_files/Urartu_subsampled_output.csv\n",
      "Wrote 238 rows to ../csv_files/History_of_Armenia_subsampled_output.csv\n",
      "Wrote 223 rows to ../csv_files/Armenian_Revolutionary_Federation_subsampled_output.csv\n",
      "Wrote 220 rows to ../csv_files/Foreign_relations_of_Armenia_subsampled_output.csv\n",
      "Wrote 187 rows to ../csv_files/Armed_Forces_of_Armenia_subsampled_output.csv\n",
      "Wrote 183 rows to ../csv_files/Armenian_Apostolic_Church_subsampled_output.csv\n",
      "Wrote 176 rows to ../csv_files/Kars_subsampled_output.csv\n",
      "Wrote 174 rows to ../csv_files/First_Republic_of_Armenia_subsampled_output.csv\n",
      "Wrote 173 rows to ../csv_files/Victory_Day_(9_May)_subsampled_output.csv\n",
      "Wrote 173 rows to ../csv_files/History_of_Nagorno-Karabakh_subsampled_output.csv\n",
      "Wrote 170 rows to ../csv_files/Lavash_subsampled_output.csv\n",
      "Wrote 162 rows to ../csv_files/Armenians_in_Turkey_subsampled_output.csv\n",
      "Wrote 156 rows to ../csv_files/Etchmiadzin_Cathedral_subsampled_output.csv\n",
      "Wrote 152 rows to ../csv_files/Nagorno-Karabakh_conflict_subsampled_output.csv\n",
      "Wrote 148 rows to ../csv_files/Armenian_diaspora_subsampled_output.csv\n",
      "Wrote 140 rows to ../csv_files/List_of_equipment_of_the_Armenian_Armed_Forces_subsampled_output.csv\n",
      "Wrote 132 rows to ../csv_files/Hemshin_people_subsampled_output.csv\n",
      "Wrote 127 rows to ../csv_files/Karabakh_subsampled_output.csv\n",
      "Wrote 117 rows to ../csv_files/Flag_of_Armenia_subsampled_output.csv\n",
      "Wrote 114 rows to ../csv_files/Armenian_Ground_Forces_subsampled_output.csv\n",
      "Wrote 112 rows to ../csv_files/Armenian_highlands_subsampled_output.csv\n",
      "Wrote 108 rows to ../csv_files/Karabakh_Khanate_subsampled_output.csv\n",
      "Wrote 104 rows to ../csv_files/Garni_Temple_subsampled_output.csv\n",
      "Wrote 104 rows to ../csv_files/Erivan_Khanate_subsampled_output.csv\n",
      "Wrote 99 rows to ../csv_files/Van_cat_subsampled_output.csv\n",
      "Wrote 98 rows to ../csv_files/Deportation_of_Armenian_intellectuals_on_24_April_1915_subsampled_output.csv\n",
      "Wrote 89 rows to ../csv_files/List_of_visitors_to_Tsitsernakaberd_subsampled_output.csv\n",
      "Wrote 87 rows to ../csv_files/Confiscation_of_Armenian_properties_in_Turkey_subsampled_output.csv\n",
      "Wrote 82 rows to ../csv_files/Demographics_of_Armenia_subsampled_output.csv\n",
      "Wrote 1182 rows to ../csv_files/Armenian genocide_subsampled_output.csv\n",
      "Wrote 106 rows to ../csv_files/Artsakh (historical province)_subsampled_output.csv\n",
      "Wrote 476 rows to ../csv_files/First Nagorno-Karabakh War_subsampled_output.csv\n",
      "Wrote 107 rows to ../csv_files/Nakhchivan (city)_subsampled_output.csv\n",
      "Wrote 372 rows to ../csv_files/Nakhchivan Autonomous Republic_subsampled_output.csv\n",
      "Wrote 457 rows to ../csv_files/Republic of Artsakh_subsampled_output.csv\n",
      "Wrote 669 rows to ../csv_files/Second Nagorno-Karabakh War_subsampled_output.csv\n",
      "Wrote 115 rows to ../csv_files/ArmeniaâAzerbaijan_border_crisis_(2021âpresent)_subsampled_output.csv\n",
      "Wrote 89 rows to ../csv_files/ArmenianâAzerbaijani_war_(1918â1920)_subsampled_output.csv\n",
      "Wrote 113 rows to ../csv_files/IÄdÄ±r_subsampled_output.csv\n",
      "Wrote 79 rows to ../csv_files/Culture_of_Armenia_subsampled_output.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Helper Functions\n",
    "# -------------------------------\n",
    "\n",
    "input_directory = \"../enriched_sample_subset\"\n",
    "\n",
    "def parse_jsonl(jsonl_path):\n",
    "    records = []\n",
    "    with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "                records.append(obj)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Skipping a line in {jsonl_path} due to JSON error: {e}\")\n",
    "    return records\n",
    "\n",
    "def parse_analysis_txt_list(analysis_path):\n",
    "    with open(analysis_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    blocks = re.split(r'-{5,}', content)\n",
    "    records = []\n",
    "    for block in blocks:\n",
    "        block = block.strip()\n",
    "        if not block:\n",
    "            continue\n",
    "        \n",
    "        rec_match = re.search(r'Record\\s+(\\d+).*?\\(Version:\\s*([^)]+)\\)', block, re.IGNORECASE)\n",
    "        if rec_match:\n",
    "            record_num = int(rec_match.group(1))\n",
    "            version_val = rec_match.group(2).strip()\n",
    "        else:\n",
    "            record_num = None\n",
    "            version_val = None\n",
    "        \n",
    "        judgment_match = re.search(r'\\*\\*Judgment:\\*\\*\\s*(.*)', block, re.IGNORECASE)\n",
    "        judgment_val = judgment_match.group(1).strip() if judgment_match else \"Not Found\"\n",
    "        #print(judgment_val)\n",
    "        analysis_match = re.search(r'\\*\\*Explanation:\\*\\*\\s*(.*)', block, re.IGNORECASE)\n",
    "        analysis_val = analysis_match.group(1).strip() if analysis_match else block\n",
    "        \n",
    "        records.append({\n",
    "            \"record\": record_num,\n",
    "            \"version\": version_val,\n",
    "            \"analysis\": analysis_val,\n",
    "            \"judgment\": judgment_val,\n",
    "            \"text\": block\n",
    "        })\n",
    "    return records\n",
    "\n",
    "# -------------------------------\n",
    "# Main Script\n",
    "# -------------------------------\n",
    "\n",
    "jsonl_files = [\n",
    "    os.path.join(input_directory, f)\n",
    "    for f in os.listdir(input_directory)\n",
    "    if f.endswith(\".jsonl\")\n",
    "]\n",
    "\n",
    "\n",
    "for json_file in jsonl_files:\n",
    "    analysis_file = json_file.replace(\"/enriched_sample_subset\", \"/txt_results\").replace(\"_enriched_subsampled.jsonl\", \"_subsampled_analysis.txt\")\n",
    "    if not os.path.exists(json_file):\n",
    "        print(f\"Skipping {json_file} - file not found.\")\n",
    "        continue\n",
    "    if not os.path.exists(analysis_file):\n",
    "        print(f\"Skipping {analysis_file} - file not found.\")\n",
    "        continue\n",
    "    \n",
    "    json_records = parse_jsonl(json_file)\n",
    "    analysis_records = parse_analysis_txt_list(analysis_file)\n",
    "    \n",
    "    num_pairs = min(len(json_records), len(analysis_records))\n",
    "    csv_rows = []\n",
    "\n",
    "    for i in range(num_pairs):\n",
    "        rec = json_records[i]\n",
    "        analysis_data = analysis_records[i]\n",
    "\n",
    "\n",
    "        analysis = analysis_data.get(\"analysis\", \"\")\n",
    "        comment = rec.get(\"Comment\", \"\")\n",
    "        if comment and comment != \"\":\n",
    "            final_text = f\"Analysis of the edit: {analysis} Comment by its editor: '{comment}'\"\n",
    "        else:\n",
    "            final_text = f\"Analysis of the edit: {analysis}\"\n",
    "\n",
    "        #print(analysis_data)\n",
    "        csv_rows.append({\n",
    "            \"Source\": json_file,\n",
    "            \"Timestamp\": rec.get(\"Timestamp\", \"\"),\n",
    "            \"User\": rec.get(\"User\", \"\"),\n",
    "            \"Comment\": rec.get(\"Comment\", \"\"),\n",
    "            \"Diff\": rec.get(\"Diff\", \"\"),\n",
    "            \"Added_Lines\": \" | \".join(rec.get(\"Added_Lines\", [])),\n",
    "            \"Removed_Lines\": \" | \".join(rec.get(\"Removed_Lines\", [])),\n",
    "            \"Added_Words\": \" | \".join(rec.get(\"Added_Words\", [])),\n",
    "            \"Removed_Words\": \" | \".join(rec.get(\"Removed_Words\", [])),\n",
    "            \"Judgment\": analysis_data.get(\"judgment\", \"\"),\n",
    "            \"Analysis\": analysis_data.get(\"analysis\", \"\"),\n",
    "            \"final_text\": final_text\n",
    "        })\n",
    "\n",
    "    # Create and save DataFrame per file\n",
    "    df = pd.DataFrame(csv_rows)\n",
    "    output_csv = json_file.replace(\"/enriched_sample_subset\", \"/csv_files\").replace(\"_enriched_subsampled.jsonl\", \"_subsampled_output.csv\")\n",
    "    df.to_csv(output_csv, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Wrote {len(csv_rows)} rows to {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "armenia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
